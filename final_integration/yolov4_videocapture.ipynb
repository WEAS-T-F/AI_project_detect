{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if len(physical_devices) > 0:\n",
    "#    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "'''python detect_video.py \n",
    "--weights ./checkpoints/custom-416 \n",
    "--size 416 \n",
    "--model yolov4 \n",
    "--video 0 \n",
    "--output \n",
    "./detections/results.avi\n",
    "\n",
    "flags.DEFINE_string('framework', 'tf', '(tf, tflite, trt')\n",
    "flags.DEFINE_string('weights', './checkpoints/custom-416/',\n",
    "                    'path to weights file')\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolo or yolo-tiny')\n",
    "flags.DEFINE_string('model', 'yolov4', 'yolov3 or yolov4')\n",
    "flags.DEFINE_string('video', '0' , 'path to input video or set to 0 for webcam')\n",
    "flags.DEFINE_string('output', './detections/results.avi', 'path to output video')\n",
    "flags.DEFINE_string('output_format', 'XVID', 'codec used in VideoWriter when saving video to file')\n",
    "flags.DEFINE_float('iou', 0.45, 'iou threshold')\n",
    "flags.DEFINE_float('score', 0.25, 'score threshold')\n",
    "flags.DEFINE_boolean('dont_show', False, 'dont show video output')\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session = InteractiveSession(config=config)\n",
    "#STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
    "weights_path = \"./checkpoints/custom-416/\"\n",
    "input_size = 416\n",
    "model = \"yolov4\"\n",
    "video_path = 0\n",
    "output = \"./detections/results.avi\"\n",
    "output_format = 'XVID'\n",
    "iou = 0.45\n",
    "score = 0.25\n",
    "dont_show = False\n",
    "saved_model_loaded = tf.saved_model.load(weights_path, tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "    # begin video capture\n",
    "try:\n",
    "    vid = cv2.VideoCapture(0)\n",
    "except:\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "out = None\n",
    "\n",
    "if output:\n",
    "    # by default VideoCapture returns float instead of int\n",
    "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    codec = cv2.VideoWriter_fourcc(*output_format)\n",
    "    out = cv2.VideoWriter(output, codec, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    return_value, frame = vid.read()\n",
    "    if return_value:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame)\n",
    "    else:\n",
    "        print('Video has ended or failed, try a different video format!')\n",
    "        break\n",
    "    \n",
    "    frame_size = frame.shape[:2]\n",
    "    image_data = cv2.resize(frame, (input_size, input_size))\n",
    "    image_data = image_data / 255.\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    start_time = time.time()\n",
    "\n",
    "   \n",
    "    batch_data = tf.constant(image_data)\n",
    "    pred_bbox = infer(batch_data)\n",
    "    for key, value in pred_bbox.items():\n",
    "        boxes = value[:, :, 0:4]\n",
    "        pred_conf = value[:, :, 4:]\n",
    "\n",
    "        \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(pred_conf,(tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "                max_output_size_per_class=50,\n",
    "                max_total_size=50,\n",
    "                iou_threshold=iou,\n",
    "                score_threshold=score\n",
    "    )\n",
    "    pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "    image = utils.draw_bbox(frame, pred_bbox)\n",
    "    #fps = 1.0 / (time.time() - start_time)\n",
    "    #print(\"FPS: %.2f\" % fps)\n",
    "    result = np.asarray(image)\n",
    "    cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "    result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "    if not dont_show:\n",
    "        cv2.imshow(\"result\", result)\n",
    "        \n",
    "    if output:\n",
    "        out.write(result)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): break\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
